<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.ferretninja.com</id>
    <title>Ferret Ninja - Yu Wang</title>
    <updated>2021-11-03T02:54:54.018Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://blog.ferretninja.com"/>
    <link rel="self" href="https://blog.ferretninja.com/atom.xml"/>
    <subtitle>Whiskers</subtitle>
    <logo>https://blog.ferretninja.com/images/avatar.png</logo>
    <icon>https://blog.ferretninja.com/favicon.ico</icon>
    <rights>All rights reserved 2021, Ferret Ninja - Yu Wang</rights>
    <entry>
        <title type="html"><![CDATA[Javascript 5 - DOM]]></title>
        <id>https://blog.ferretninja.com/post/javascript-5-dom/</id>
        <link href="https://blog.ferretninja.com/post/javascript-5-dom/">
        </link>
        <updated>2021-06-28T20:41:41.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://blog.ferretninja.com/post-images/1590533131285.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://blog.ferretninja.com/post-images/1590533375585.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://blog.ferretninja.com/post-images/1590533753402.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="4"><img src="https://blog.ferretninja.com/post-images/1590536478146.png" alt="" loading="lazy"></figure>
<p><img src="https://blog.ferretninja.com/post-images/1590546015133.png" alt="" loading="lazy"><br>
<img src="https://blog.ferretninja.com/post-images/1590551341532.png" alt="" loading="lazy"></p>
<figure data-type="image" tabindex="5"><img src="https://blog.ferretninja.com/post-images/1590551353706.png" alt="" loading="lazy"></figure>
<p><img src="https://blog.ferretninja.com/post-images/1590551365472.png" alt="" loading="lazy"><br>
<img src="https://blog.ferretninja.com/post-images/1590551374368.png" alt="" loading="lazy"></p>
<p>position: absolute;<br>
An element with position: absolute; is positioned relative to the nearest positioned ancestor</p>
<p>position: relative;<br>
An element with position: relative; is positioned relative to its normal position.</p>
<pre><code>&lt;div id=&quot;box1&quot;&gt;&lt;!--参照定位的元素--&gt;
    &lt;div id=&quot;box2&quot;&gt;相对参照元素进行定位&lt;/div&gt;&lt;!--相对定位元素--&gt;
&lt;/div&gt;

#box1{
    width:200px;
    height:200px;
    position:relative;        
} 
#box2{
    position:absolute;
    top:20px;
    left:30px;         
}
</code></pre>
<p>**已知宽高实现盒子水平垂直居中 **</p>
<pre><code>&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;已知宽高实现盒子水平垂直居中&lt;/title&gt;
    &lt;style type=&quot;text/css&quot;&gt;
    .box {
        border: 1px solid #00ee00;
        height: 300px;
        position: relative;
    }

    .box1 {
        position: absolute;
        top: 50%;
        left: 50%;
        margin: -100px 0px 0px -100px;
        
        width: 200px;
        height: 200px;
        border: 1px solid red;
    }
    &lt;/style&gt;
&lt;/head&gt;

&lt;body&gt;
    &lt;div class=&quot;box&quot;&gt;
        &lt;div class=&quot;box1&quot;&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
</code></pre>
<p>宽高不定实现盒子水平垂直居中</p>
<pre><code>&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;宽高不定实现盒子水平垂直居中&lt;/title&gt;
    &lt;style type=&quot;text/css&quot;&gt;
    .box {
        border: 1px solid #00ee00;
        height: 300px;
        position: relative;
    }

    .box1 {
        border: 1px solid red;
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
    }
    &lt;/style&gt;
&lt;/head&gt;

&lt;body&gt;
    &lt;div class=&quot;box&quot;&gt;
        &lt;div class=&quot;box1&quot;&gt;
            网网网网网网网网网网网网网网网网网网网网网网
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/body&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Javascript 4 - ES6]]></title>
        <id>https://blog.ferretninja.com/post/javascript-4-es6/</id>
        <link href="https://blog.ferretninja.com/post/javascript-4-es6/">
        </link>
        <updated>2021-05-25T20:41:18.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://blog.ferretninja.com/post-images/1588020833158.png" alt="" loading="lazy"></figure>
<p><strong>let/const block scope</strong></p>
<pre><code>let arr = [1,2,3,4]
for (let i = 0; i &lt; arr.length; i++) {
}
console.log(i); // error

let arr = [1,2,3,4]
for (var i = 0; i &lt; arr.length; i++) {
}
console.log(i); // 4
</code></pre>
<p><strong>Hoisting</strong></p>
<pre><code>console.log(foo);
var foo = 1;
</code></pre>
<p><strong>Arrow function</strong></p>
<p>Arrow function no this, cannot be constructor, no prototype</p>
<pre><code>// 函数声明
function test() {}
// 函数表达式
const test = function() {}
// 箭头函数
const test = () =&gt; {}

var obj = {
	commonFn : function() {
		console.log(this);
	},
	arrowFn : () =&gt; {
		console.log(this);
	}
}

obj.commonFn();
obj.arrowFn();
VM372:3 {commonFn: ƒ, arrowFn: ƒ}
VM372:6 Window {parent: Window, opener: null, top: Window, length: 2, frames: Window, …}
</code></pre>
<p><strong>Template string</strong></p>
<pre><code>let getName = () =&gt; {
    return 'test';
}
let str = `
&lt;div&gt;
 &lt;h1 class = &quot;title&quot;&gt;${getName()}&lt;/h1&gt;
&lt;/div&gt;
`;
document.querySelector('body').innerHTML = str;
</code></pre>
<p><strong>object</strong></p>
<pre><code>var name = 'test',
	age = 18;
var obj = {
	name: name,
	age: age,
	getName: function() {
		return this.name;
	},
	getAge: function() {
		return this.age;
	}
}

let name = 'test',
	age = 18;
let obj = {
	name,
	age,
	getName() {
		return this.name;
	},
	['get' + 'Age']() {
		return this.age;
	}
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Javascript 3 - http request]]></title>
        <id>https://blog.ferretninja.com/post/javascript-3-http-request/</id>
        <link href="https://blog.ferretninja.com/post/javascript-3-http-request/">
        </link>
        <updated>2021-04-20T20:40:59.000Z</updated>
        <content type="html"><![CDATA[<p><strong>url parsing</strong><br>
<img src="https://blog.ferretninja.com/post-images/1588015088492.png" alt="" loading="lazy"></p>
<p><strong>dns</strong><br>
<img src="https://blog.ferretninja.com/post-images/1588015159663.png" alt="" loading="lazy"></p>
<p><strong>request</strong><br>
<img src="https://blog.ferretninja.com/post-images/1588015638581.png" alt="" loading="lazy"></p>
<p><strong>dom</strong><br>
<img src="https://blog.ferretninja.com/post-images/1588015705473.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Javascript 2 - Chrome dev tools]]></title>
        <id>https://blog.ferretninja.com/post/javascript-2-chrome-dev-tools/</id>
        <link href="https://blog.ferretninja.com/post/javascript-2-chrome-dev-tools/">
        </link>
        <updated>2021-03-29T09:40:40.000Z</updated>
        <content type="html"><![CDATA[<p>ctrl + shift + i open dev tools<br>
ctrl + shift + C select element</p>
<p>network: request status</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[AWS Redshift and Apache Airflow pipeline]]></title>
        <id>https://blog.ferretninja.com/post/aws-redshift-and-apache-airflow-pipeline/</id>
        <link href="https://blog.ferretninja.com/post/aws-redshift-and-apache-airflow-pipeline/">
        </link>
        <updated>2021-03-29T09:36:56.000Z</updated>
        <content type="html"><![CDATA[<p>A reusable production-grade data pipeline that incorporates data quality checks and allows for easy backfills. The source data resides in S3 and needs to be processed in a data warehouse in Amazon Redshift. The source datasets consist of JSON logs that tell about user activity in the application and JSON metadata about the songs the users listen to.</p>
<ol>
<li>
<p>Create AWS redshift cluster and test queries.<br>
<img src="https://blog.ferretninja.com/post-images/1573755046671.png" alt="" loading="lazy"></p>
</li>
<li>
<p>Set up AWS S3 hook<br>
<img src="https://blog.ferretninja.com/post-images/1573760821111.png" alt="" loading="lazy"></p>
</li>
<li>
<p>Set up redshift connection hook<br>
<img src="https://blog.ferretninja.com/post-images/1573760949674.png" alt="" loading="lazy"></p>
</li>
<li>
<p>Set up Airflow job DAG<br>
<img src="https://blog.ferretninja.com/post-images/1573778681268.png" alt="" loading="lazy"></p>
</li>
<li>
<p>Run Airflow scheduler<br>
<img src="https://blog.ferretninja.com/post-images/1573778839068.png" alt="" loading="lazy"></p>
</li>
<li>
<p>See past job statistics<br>
<img src="https://blog.ferretninja.com/post-images/1573779317276.png" alt="" loading="lazy"></p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[AWS EMR Spark and Data Lake]]></title>
        <id>https://blog.ferretninja.com/post/aws-emr-spark-and-data-lake/</id>
        <link href="https://blog.ferretninja.com/post/aws-emr-spark-and-data-lake/">
        </link>
        <updated>2021-03-29T09:36:28.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://blog.ferretninja.com/post-images/1573690987278.png" alt="" loading="lazy"></figure>
<p>An ETL pipeline that extracts data from S3, processes them using Spark, and loads the data back into S3 as a set of dimensional tables.</p>
<p>Create a Data Lake with Spark and AWS EMR</p>
<ol>
<li>create a ssh key-pair to securely connect to the EMR cluster</li>
<li>create an EMR cluster<br>
<img src="https://blog.ferretninja.com/post-images/1573691132968.png" alt="" loading="lazy"><br>
<img src="https://blog.ferretninja.com/post-images/1573691150215.png" alt="" loading="lazy"></li>
<li>ssh into the master node<br>
<img src="https://blog.ferretninja.com/post-images/1573691211629.png" alt="" loading="lazy"></li>
<li>access master node jupyter notebook<br>
<img src="https://blog.ferretninja.com/post-images/1573691449872.png" alt="" loading="lazy"></li>
</ol>
<pre><code class="language-python">print(&quot;Welcome to my EMR Notebook!&quot;)
</code></pre>
<pre><code>VBox()


Starting Spark application
</code></pre>
<table>
<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1573680517609_0004</td><td>pyspark</td><td>idle</td><td><a target="_blank" href="http://ip-172-31-90-61.ec2.internal:20888/proxy/application_1573680517609_0004/">Link</a></td><td><a target="_blank" href="http://ip-172-31-94-174.ec2.internal:8042/node/containerlogs/container_1573680517609_0004_01_000001/livy">Link</a></td><td>✔</td></tr></table>
<pre><code>FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…


SparkSession available as 'spark'.



FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…


Welcome to my EMR Notebook!
</code></pre>
<pre><code class="language-python">%%info
</code></pre>
<p>Current session configs: <tt>{'conf': {'spark.pyspark.python': 'python3', 'spark.pyspark.virtualenv.enabled': 'true', 'spark.pyspark.virtualenv.type': 'native', 'spark.pyspark.virtualenv.bin.path': '/usr/bin/virtualenv'}, 'kind': 'pyspark'}</tt><br></p>
<table>
<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1573680517609_0004</td><td>pyspark</td><td>idle</td><td><a target="_blank" href="http://ip-172-31-90-61.ec2.internal:20888/proxy/application_1573680517609_0004/">Link</a></td><td><a target="_blank" href="http://ip-172-31-94-174.ec2.internal:8042/node/containerlogs/container_1573680517609_0004_01_000001/livy">Link</a></td><td>✔</td></tr></table>
<pre><code class="language-python">sc.list_packages()
</code></pre>
<pre><code>VBox()



FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…


Package                    Version
-------------------------- -------
beautifulsoup4             4.8.1  
boto                       2.49.0 
jmespath                   0.9.4  
lxml                       4.4.1  
mysqlclient                1.4.4  
nltk                       3.4.5  
nose                       1.3.4  
numpy                      1.14.5 
pip                        19.3.1 
py-dateutil                2.2    
python36-sagemaker-pyspark 1.2.6  
pytz                       2019.3 
PyYAML                     3.11   
setuptools                 41.6.0 
six                        1.12.0 
soupsieve                  1.9.4  
wheel                      0.33.6 
windmill                   1.6
</code></pre>
<pre><code class="language-python">sc.install_pypi_package(&quot;pandas==0.25.1&quot;)
</code></pre>
<pre><code>VBox()



FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…


Collecting pandas==0.25.1
  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)
Requirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib64/python3.6/site-packages (from pandas==0.25.1) (1.14.5)
Collecting python-dateutil&gt;=2.6.1
  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas==0.25.1) (2019.3)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil&gt;=2.6.1-&gt;pandas==0.25.1) (1.12.0)
Installing collected packages: python-dateutil, pandas
Successfully installed pandas-0.25.1 python-dateutil-2.8.1
</code></pre>
<pre><code class="language-python">sc.install_pypi_package(&quot;matplotlib&quot;, &quot;https://pypi.org/simple&quot;) #Install matplotlib from given PyPI repository
</code></pre>
<pre><code>VBox()



FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…


Collecting matplotlib
  Downloading https://files.pythonhosted.org/packages/57/4f/dd381ecf6c6ab9bcdaa8ea912e866dedc6e696756156d8ecc087e20817e2/matplotlib-3.1.1-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)
Requirement already satisfied: numpy&gt;=1.11 in /usr/local/lib64/python3.6/site-packages (from matplotlib) (1.14.5)
Collecting kiwisolver&gt;=1.0.1
  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)
Requirement already satisfied: python-dateutil&gt;=2.1 in /mnt/tmp/1573683191129-0/lib/python3.6/site-packages (from matplotlib) (2.8.1)
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1
  Downloading https://files.pythonhosted.org/packages/c0/0c/fc2e007d9a992d997f04a80125b0f183da7fb554f1de701bbb70a8e7d479/pyparsing-2.4.5-py2.py3-none-any.whl (67kB)
Collecting cycler&gt;=0.10
  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl
Requirement already satisfied: setuptools in /mnt/tmp/1573683191129-0/lib/python3.6/site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib) (41.6.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil&gt;=2.1-&gt;matplotlib) (1.12.0)
Installing collected packages: kiwisolver, pyparsing, cycler, matplotlib
Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.1 pyparsing-2.4.5
</code></pre>
<pre><code class="language-python">sc.list_packages()
</code></pre>
<pre><code>VBox()



FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…


Package                    Version
-------------------------- -------
beautifulsoup4             4.8.1  
boto                       2.49.0 
cycler                     0.10.0 
jmespath                   0.9.4  
kiwisolver                 1.1.0  
lxml                       4.4.1  
matplotlib                 3.1.1  
mysqlclient                1.4.4  
nltk                       3.4.5  
nose                       1.3.4  
numpy                      1.14.5 
pandas                     0.25.1 
pip                        19.3.1 
py-dateutil                2.2    
pyparsing                  2.4.5  
python-dateutil            2.8.1  
python36-sagemaker-pyspark 1.2.6  
pytz                       2019.3 
PyYAML                     3.11   
setuptools                 41.6.0 
six                        1.12.0 
soupsieve                  1.9.4  
wheel                      0.33.6 
windmill                   1.6
</code></pre>
<pre><code class="language-python">df = spark.read.parquet('s3://amazon-reviews-pds/parquet/product_category=Books/*.parquet')
</code></pre>
<pre><code>VBox()



FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…
</code></pre>
<pre><code class="language-python">df.printSchema()
num_of_books = df.select('product_id').distinct().count()
print(f'Number of Books: {num_of_books:,}')
</code></pre>
<pre><code>VBox()



FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…


root
 |-- marketplace: string (nullable = true)
 |-- customer_id: string (nullable = true)
 |-- review_id: string (nullable = true)
 |-- product_id: string (nullable = true)
 |-- product_parent: string (nullable = true)
 |-- product_title: string (nullable = true)
 |-- star_rating: integer (nullable = true)
 |-- helpful_votes: integer (nullable = true)
 |-- total_votes: integer (nullable = true)
 |-- vine: string (nullable = true)
 |-- verified_purchase: string (nullable = true)
 |-- review_headline: string (nullable = true)
 |-- review_body: string (nullable = true)
 |-- review_date: date (nullable = true)
 |-- year: integer (nullable = true)

Number of Books: 3,423,743
</code></pre>
<ol start="5">
<li>install python libraries</li>
</ol>
<pre><code>sudo easy_install-3.6 pip 
sudo /usr/local/bin/pip3 install paramiko nltk scipy scikit-learn pandas
</code></pre>
<ol start="6">
<li>
<p>upload file to EMR<br>
<img src="https://blog.ferretninja.com/post-images/1573691565612.png" alt="" loading="lazy"></p>
</li>
<li>
<p>spark-submit job</p>
</li>
</ol>
<pre><code class="language-python">import configparser
from datetime import datetime
import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, col
from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format
from pyspark.sql import functions as F
from pyspark.sql import types as T

import pandas as pd
pd.set_option('display.max_columns', 500)
</code></pre>
<pre><code class="language-python">config = configparser.ConfigParser()

#Normally this file should be in ~/.aws/credentials
config.read_file(open('dl.cfg'))

os.environ[&quot;AWS_ACCESS_KEY_ID&quot;]= config['AWS']['AWS_ACCESS_KEY_ID']
os.environ[&quot;AWS_SECRET_ACCESS_KEY&quot;]= config['AWS']['AWS_SECRET_ACCESS_KEY']
</code></pre>
<pre><code class="language-python">def create_spark_session():
    spark = SparkSession \
        .builder \
        .config(&quot;spark.jars.packages&quot;, &quot;org.apache.hadoop:hadoop-aws:2.7.0&quot;) \
        .getOrCreate()
    return spark
</code></pre>
<pre><code class="language-python"># create the spark session
spark = create_spark_session()
</code></pre>
<pre><code class="language-python"># read data from my S3 bucket. This is the same data in workspace
songPath = 's3a://testemrs3/song_data/*/*/*/*.json'
logPath = 's3a://testemrs3/log_data/*.json'
</code></pre>
<pre><code class="language-python"># define output paths
output = 's3a://testemrs3/schema/'
</code></pre>
<h2 id="process-song-data">process song data</h2>
<h3 id="create-song_table">create song_table</h3>
<pre><code class="language-python"># Step 1: Read in the song data
df_song = spark.read.json(songPath)
</code></pre>
<pre><code class="language-python"># check the schema
df_song.printSchema()
</code></pre>
<pre><code>root
 |-- artist_id: string (nullable = true)
 |-- artist_latitude: double (nullable = true)
 |-- artist_location: string (nullable = true)
 |-- artist_longitude: double (nullable = true)
 |-- artist_name: string (nullable = true)
 |-- duration: double (nullable = true)
 |-- num_songs: long (nullable = true)
 |-- song_id: string (nullable = true)
 |-- title: string (nullable = true)
 |-- year: long (nullable = true)
</code></pre>
<pre><code class="language-python"># Step 2: extract columns to create songs table
song_cols = ['song_id', 'title', 'artist_id', 'year', 'duration']
</code></pre>
<pre><code class="language-python"># groupby song_id and select the first record's title in the group.
t1 = df_song.select(F.col('song_id'), 'title') \
    .groupBy('song_id') \
    .agg({'title': 'first'}) \
    .withColumnRenamed('first(title)', 'title1')

t2 = df_song.select(song_cols)
</code></pre>
<pre><code class="language-python">t1.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_id</th>
      <th>title1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SOGOSOV12AF72A285E</td>
      <td>¿Dónde va Chichi?</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SOMZWCG12A8C13C480</td>
      <td>I Didn't Mean To</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SOUPIRU12A6D4FA1E1</td>
      <td>Der Kleine Dompfaff</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SOXVLOJ12AB0189215</td>
      <td>Amor De Cabaret</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SOWTBJW12AC468AC6E</td>
      <td>Broken-Down Merry-Go-Round</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">t2.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_id</th>
      <th>title</th>
      <th>artist_id</th>
      <th>year</th>
      <th>duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SOBAYLL12A8C138AF9</td>
      <td>Sono andati? Fingevo di dormire</td>
      <td>ARDR4AC1187FB371A1</td>
      <td>0</td>
      <td>511.16363</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SOOLYAZ12A6701F4A6</td>
      <td>Laws Patrolling (Album Version)</td>
      <td>AREBBGV1187FB523D2</td>
      <td>0</td>
      <td>173.66159</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SOBBUGU12A8C13E95D</td>
      <td>Setting Fire to Sleeping Giants</td>
      <td>ARMAC4T1187FB3FA4C</td>
      <td>2004</td>
      <td>207.77751</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SOAOIBZ12AB01815BE</td>
      <td>I Hold Your Hand In Mine [Live At Royal Albert...</td>
      <td>ARPBNLO1187FB3D52F</td>
      <td>2000</td>
      <td>43.36281</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SONYPOM12A8C13B2D7</td>
      <td>I Think My Wife Is Running Around On Me (Taco ...</td>
      <td>ARDNS031187B9924F0</td>
      <td>2005</td>
      <td>186.48771</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">song_table_df = t1.join(t2, 'song_id') \
                .where(F.col(&quot;title1&quot;) == F.col(&quot;title&quot;)) \
                .select(song_cols)
</code></pre>
<pre><code class="language-python">song_table_df.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_id</th>
      <th>title</th>
      <th>artist_id</th>
      <th>year</th>
      <th>duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SOBAYLL12A8C138AF9</td>
      <td>Sono andati? Fingevo di dormire</td>
      <td>ARDR4AC1187FB371A1</td>
      <td>0</td>
      <td>511.16363</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SOOLYAZ12A6701F4A6</td>
      <td>Laws Patrolling (Album Version)</td>
      <td>AREBBGV1187FB523D2</td>
      <td>0</td>
      <td>173.66159</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SOBBUGU12A8C13E95D</td>
      <td>Setting Fire to Sleeping Giants</td>
      <td>ARMAC4T1187FB3FA4C</td>
      <td>2004</td>
      <td>207.77751</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SOAOIBZ12AB01815BE</td>
      <td>I Hold Your Hand In Mine [Live At Royal Albert...</td>
      <td>ARPBNLO1187FB3D52F</td>
      <td>2000</td>
      <td>43.36281</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SONYPOM12A8C13B2D7</td>
      <td>I Think My Wife Is Running Around On Me (Taco ...</td>
      <td>ARDNS031187B9924F0</td>
      <td>2005</td>
      <td>186.48771</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">song_table_df.toPandas().shape
</code></pre>
<pre><code>(71, 5)
</code></pre>
<pre><code class="language-python">df_song.toPandas().shape
</code></pre>
<pre><code>(71, 10)
</code></pre>
<pre><code class="language-python"># Step 3: Write this to a parquet file
song_table_df.write.parquet('data/songs_table', partitionBy=['year', 'artist_id'], mode='Overwrite')
</code></pre>
<pre><code class="language-python"># write this to s3 bucket
song_table_df.write.parquet(output + 'songs_table', partitionBy=['year', 'artist_id'], mode='Overwrite')
</code></pre>
<h3 id="create-artists_table">create artists_table</h3>
<pre><code class="language-python"># define the cols
artists_cols = [&quot;artist_id&quot;, &quot;artist_name&quot;, &quot;artist_location&quot;, &quot;artist_latitude&quot;, &quot;artist_longitude&quot;]
</code></pre>
<pre><code class="language-python">df_song.printSchema()
</code></pre>
<pre><code>root
 |-- artist_id: string (nullable = true)
 |-- artist_latitude: double (nullable = true)
 |-- artist_location: string (nullable = true)
 |-- artist_longitude: double (nullable = true)
 |-- artist_name: string (nullable = true)
 |-- duration: double (nullable = true)
 |-- num_songs: long (nullable = true)
 |-- song_id: string (nullable = true)
 |-- title: string (nullable = true)
 |-- year: long (nullable = true)
</code></pre>
<pre><code class="language-python"># groupby song_id and select the first record's title in the group.
t1 = df_song.select(F.col('artist_id'), 'artist_name') \
    .groupBy('artist_id') \
    .agg({'artist_name': 'first'}) \
    .withColumnRenamed('first(artist_name)', 'artist_name1')

t2 = df_song.select(artists_cols)
</code></pre>
<pre><code class="language-python">t1.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist_id</th>
      <th>artist_name1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AR9AWNF1187B9AB0B4</td>
      <td>Kenny G featuring Daryl Hall</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AR0IAWL1187B9A96D0</td>
      <td>Danilo Perez</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AR0RCMP1187FB3F427</td>
      <td>Billie Jo Spears</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AREDL271187FB40F44</td>
      <td>Soul Mekanik</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ARI3BMM1187FB4255E</td>
      <td>Alice Stuart</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">t2.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist_id</th>
      <th>artist_name</th>
      <th>artist_location</th>
      <th>artist_latitude</th>
      <th>artist_longitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ARDR4AC1187FB371A1</td>
      <td>Montserrat Caballé;Placido Domingo;Vicente Sar...</td>
      <td></td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AREBBGV1187FB523D2</td>
      <td>Mike Jones (Featuring CJ_ Mello &amp; Lil' Bran)</td>
      <td>Houston, TX</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ARMAC4T1187FB3FA4C</td>
      <td>The Dillinger Escape Plan</td>
      <td>Morris Plains, NJ</td>
      <td>40.82624</td>
      <td>-74.47995</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ARPBNLO1187FB3D52F</td>
      <td>Tiny Tim</td>
      <td>New York, NY</td>
      <td>40.71455</td>
      <td>-74.00712</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ARDNS031187B9924F0</td>
      <td>Tim Wilson</td>
      <td>Georgia</td>
      <td>32.67828</td>
      <td>-83.22295</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">artists_table_df = t1.join(t2, 'artist_id') \
                .where(F.col(&quot;artist_name1&quot;) == F.col(&quot;artist_name&quot;)) \
                .select(artists_cols)
</code></pre>
<pre><code class="language-python">artists_table_df.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist_id</th>
      <th>artist_name</th>
      <th>artist_location</th>
      <th>artist_latitude</th>
      <th>artist_longitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ARDR4AC1187FB371A1</td>
      <td>Montserrat Caballé;Placido Domingo;Vicente Sar...</td>
      <td></td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AREBBGV1187FB523D2</td>
      <td>Mike Jones (Featuring CJ_ Mello &amp; Lil' Bran)</td>
      <td>Houston, TX</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ARMAC4T1187FB3FA4C</td>
      <td>The Dillinger Escape Plan</td>
      <td>Morris Plains, NJ</td>
      <td>40.82624</td>
      <td>-74.47995</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ARPBNLO1187FB3D52F</td>
      <td>Tiny Tim</td>
      <td>New York, NY</td>
      <td>40.71455</td>
      <td>-74.00712</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ARDNS031187B9924F0</td>
      <td>Tim Wilson</td>
      <td>Georgia</td>
      <td>32.67828</td>
      <td>-83.22295</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python"># write this to s3 bucket
artists_table_df.write.parquet(output + 'artists_table', mode='Overwrite')
</code></pre>
<pre><code class="language-python">artists_table_df.write.parquet('data/artists_table', mode='Overwrite')
</code></pre>
<pre><code class="language-python"># read the partitioned data
df_artists_read = spark.read.option(&quot;mergeSchema&quot;, &quot;true&quot;).parquet(&quot;data/artists_table&quot;)
</code></pre>
<h2 id="process-log-data">Process log data</h2>
<pre><code class="language-python"># Step 1: Read in the log data
df_log = spark.read.json(logPath)
</code></pre>
<pre><code class="language-python">df_log.printSchema()
</code></pre>
<pre><code>root
 |-- artist: string (nullable = true)
 |-- auth: string (nullable = true)
 |-- firstName: string (nullable = true)
 |-- gender: string (nullable = true)
 |-- itemInSession: long (nullable = true)
 |-- lastName: string (nullable = true)
 |-- length: double (nullable = true)
 |-- level: string (nullable = true)
 |-- location: string (nullable = true)
 |-- method: string (nullable = true)
 |-- page: string (nullable = true)
 |-- registration: double (nullable = true)
 |-- sessionId: long (nullable = true)
 |-- song: string (nullable = true)
 |-- status: long (nullable = true)
 |-- ts: long (nullable = true)
 |-- userAgent: string (nullable = true)
 |-- userId: string (nullable = true)
</code></pre>
<pre><code class="language-python">df_log.filter(F.col(&quot;page&quot;) == &quot;NextSong&quot;).toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>auth</th>
      <th>firstName</th>
      <th>gender</th>
      <th>itemInSession</th>
      <th>lastName</th>
      <th>length</th>
      <th>level</th>
      <th>location</th>
      <th>method</th>
      <th>page</th>
      <th>registration</th>
      <th>sessionId</th>
      <th>song</th>
      <th>status</th>
      <th>ts</th>
      <th>userAgent</th>
      <th>userId</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Harmonia</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>0</td>
      <td>Smith</td>
      <td>655.77751</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.541017e+12</td>
      <td>583</td>
      <td>Sehr kosmisch</td>
      <td>200</td>
      <td>1542241826796</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The Prodigy</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>1</td>
      <td>Smith</td>
      <td>260.07465</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.541017e+12</td>
      <td>583</td>
      <td>The Big Gundown</td>
      <td>200</td>
      <td>1542242481796</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Train</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>2</td>
      <td>Smith</td>
      <td>205.45261</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.541017e+12</td>
      <td>583</td>
      <td>Marry Me</td>
      <td>200</td>
      <td>1542242741796</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sony Wonder</td>
      <td>Logged In</td>
      <td>Samuel</td>
      <td>M</td>
      <td>0</td>
      <td>Gonzalez</td>
      <td>218.06975</td>
      <td>free</td>
      <td>Houston-The Woodlands-Sugar Land, TX</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.540493e+12</td>
      <td>597</td>
      <td>Blackbird</td>
      <td>200</td>
      <td>1542253449796</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>61</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Van Halen</td>
      <td>Logged In</td>
      <td>Tegan</td>
      <td>F</td>
      <td>2</td>
      <td>Levine</td>
      <td>289.38404</td>
      <td>paid</td>
      <td>Portland-South Portland, ME</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.540794e+12</td>
      <td>602</td>
      <td>Best Of Both Worlds (Remastered Album Version)</td>
      <td>200</td>
      <td>1542260935796</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>80</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python"># Step 2: filter by actions for song plays
df_log = df_log.filter(F.col(&quot;page&quot;) == &quot;NextSong&quot;)
</code></pre>
<pre><code class="language-python">df_log.toPandas().shape
</code></pre>
<pre><code>(6820, 18)
</code></pre>
<pre><code class="language-python"># Step 3: extract columns for users table
users_cols = [&quot;userId&quot;, &quot;firstName&quot;, &quot;lastName&quot;, &quot;gender&quot;, &quot;level&quot;]
</code></pre>
<pre><code class="language-python">df_log.select(users_cols).toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>firstName</th>
      <th>lastName</th>
      <th>gender</th>
      <th>level</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>26</td>
      <td>Ryan</td>
      <td>Smith</td>
      <td>M</td>
      <td>free</td>
    </tr>
    <tr>
      <th>1</th>
      <td>26</td>
      <td>Ryan</td>
      <td>Smith</td>
      <td>M</td>
      <td>free</td>
    </tr>
    <tr>
      <th>2</th>
      <td>26</td>
      <td>Ryan</td>
      <td>Smith</td>
      <td>M</td>
      <td>free</td>
    </tr>
    <tr>
      <th>3</th>
      <td>61</td>
      <td>Samuel</td>
      <td>Gonzalez</td>
      <td>M</td>
      <td>free</td>
    </tr>
    <tr>
      <th>4</th>
      <td>80</td>
      <td>Tegan</td>
      <td>Levine</td>
      <td>F</td>
      <td>paid</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">df_log.select(users_cols).toPandas().shape
</code></pre>
<pre><code>(6820, 5)
</code></pre>
<pre><code class="language-python">df_log.select(users_cols).dropDuplicates().toPandas().shape
</code></pre>
<pre><code>(104, 5)
</code></pre>
<pre><code class="language-python">df_log.select(users_cols).dropDuplicates().toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>firstName</th>
      <th>lastName</th>
      <th>gender</th>
      <th>level</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>57</td>
      <td>Katherine</td>
      <td>Gay</td>
      <td>F</td>
      <td>free</td>
    </tr>
    <tr>
      <th>1</th>
      <td>84</td>
      <td>Shakira</td>
      <td>Hunt</td>
      <td>F</td>
      <td>free</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>Sean</td>
      <td>Wilson</td>
      <td>F</td>
      <td>free</td>
    </tr>
    <tr>
      <th>3</th>
      <td>52</td>
      <td>Theodore</td>
      <td>Smith</td>
      <td>M</td>
      <td>free</td>
    </tr>
    <tr>
      <th>4</th>
      <td>80</td>
      <td>Tegan</td>
      <td>Levine</td>
      <td>F</td>
      <td>paid</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">users_table_df = df_log.select(users_cols).dropDuplicates()
</code></pre>
<pre><code class="language-python"># write this to s3 bucket
users_table_df.write.parquet(output + 'users_table', mode='Overwrite')
</code></pre>
<pre><code class="language-python">users_table_df.write.parquet('data/users_table', mode='Overwrite')
</code></pre>
<h2 id="time-table">Time table</h2>
<pre><code class="language-python"># # create timestamp column from original timestamp column
get_timestamp = udf()
</code></pre>
<pre><code class="language-python">df_log.select('ts').toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1542241826796</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1542242481796</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1542242741796</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1542253449796</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1542260935796</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">df.withColumn('epoch', f.date_format(df.epoch.cast(dataType=t.TimestampType()), &quot;yyyy-MM-dd&quot;))
</code></pre>
<pre><code class="language-python">
</code></pre>
<pre><code class="language-python">df_log.withColumn('ts', F.date_format(df_log.ts.cast(dataType=T.TimestampType()), &quot;yyyy-MM-dd&quot;)).toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>auth</th>
      <th>firstName</th>
      <th>gender</th>
      <th>itemInSession</th>
      <th>lastName</th>
      <th>length</th>
      <th>level</th>
      <th>location</th>
      <th>method</th>
      <th>page</th>
      <th>registration</th>
      <th>sessionId</th>
      <th>song</th>
      <th>status</th>
      <th>ts</th>
      <th>userAgent</th>
      <th>userId</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Harmonia</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>0</td>
      <td>Smith</td>
      <td>655.77751</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.541017e+12</td>
      <td>583</td>
      <td>Sehr kosmisch</td>
      <td>200</td>
      <td>50841-09-12</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The Prodigy</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>1</td>
      <td>Smith</td>
      <td>260.07465</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.541017e+12</td>
      <td>583</td>
      <td>The Big Gundown</td>
      <td>200</td>
      <td>50841-09-19</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Train</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>2</td>
      <td>Smith</td>
      <td>205.45261</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.541017e+12</td>
      <td>583</td>
      <td>Marry Me</td>
      <td>200</td>
      <td>50841-09-22</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sony Wonder</td>
      <td>Logged In</td>
      <td>Samuel</td>
      <td>M</td>
      <td>0</td>
      <td>Gonzalez</td>
      <td>218.06975</td>
      <td>free</td>
      <td>Houston-The Woodlands-Sugar Land, TX</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.540493e+12</td>
      <td>597</td>
      <td>Blackbird</td>
      <td>200</td>
      <td>50842-01-24</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>61</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Van Halen</td>
      <td>Logged In</td>
      <td>Tegan</td>
      <td>F</td>
      <td>2</td>
      <td>Levine</td>
      <td>289.38404</td>
      <td>paid</td>
      <td>Portland-South Portland, ME</td>
      <td>PUT</td>
      <td>NextSong</td>
      <td>1.540794e+12</td>
      <td>602</td>
      <td>Best Of Both Worlds (Remastered Album Version)</td>
      <td>200</td>
      <td>50842-04-21</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>80</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">df_time = df_log.select('ts')
</code></pre>
<pre><code class="language-python">df_time.take(5)
</code></pre>
<pre><code>[Row(ts=1542241826796),
 Row(ts=1542242481796),
 Row(ts=1542242741796),
 Row(ts=1542253449796),
 Row(ts=1542260935796)]
</code></pre>
<pre><code class="language-python">@udf
def gettimestamp(time):
    import datetime
    time = time/1000
    return datetime.datetime.fromtimestamp(time).strftime(&quot;%m-%d-%Y %H:%M:%S&quot;)
</code></pre>
<pre><code class="language-python">df_time.withColumn(&quot;timestamp&quot;, gettimestamp(&quot;ts&quot;)).show()
</code></pre>
<pre><code>+-------------+-------------------+
|           ts|          timestamp|
+-------------+-------------------+
|1542241826796|11-15-2018 00:30:26|
|1542242481796|11-15-2018 00:41:21|
|1542242741796|11-15-2018 00:45:41|
|1542253449796|11-15-2018 03:44:09|
|1542260935796|11-15-2018 05:48:55|
|1542261224796|11-15-2018 05:53:44|
|1542261356796|11-15-2018 05:55:56|
|1542261662796|11-15-2018 06:01:02|
|1542262057796|11-15-2018 06:07:37|
|1542262233796|11-15-2018 06:10:33|
|1542262434796|11-15-2018 06:13:54|
|1542262456796|11-15-2018 06:14:16|
|1542262679796|11-15-2018 06:17:59|
|1542262728796|11-15-2018 06:18:48|
|1542262893796|11-15-2018 06:21:33|
|1542263158796|11-15-2018 06:25:58|
|1542263378796|11-15-2018 06:29:38|
|1542265716796|11-15-2018 07:08:36|
|1542265929796|11-15-2018 07:12:09|
|1542266927796|11-15-2018 07:28:47|
+-------------+-------------------+
only showing top 20 rows
</code></pre>
<pre><code class="language-python">df_time.printSchema()
</code></pre>
<pre><code>root
 |-- ts: long (nullable = true)
</code></pre>
<pre><code class="language-python">
</code></pre>
<pre><code class="language-python">get_timestamp = F.udf(lambda x: datetime.fromtimestamp( (x/1000.0) ), T.TimestampType()) 
get_hour = F.udf(lambda x: x.hour, T.IntegerType()) 
get_day = F.udf(lambda x: x.day, T.IntegerType()) 
get_week = F.udf(lambda x: x.isocalendar()[1], T.IntegerType()) 
get_month = F.udf(lambda x: x.month, T.IntegerType()) 
get_year = F.udf(lambda x: x.year, T.IntegerType()) 
get_weekday = F.udf(lambda x: x.weekday(), T.IntegerType()) 
</code></pre>
<pre><code class="language-python">df_log = df_log.withColumn(&quot;timestamp&quot;, get_timestamp(df_log.ts))
df_log = df_log.withColumn(&quot;hour&quot;, get_hour(df_log.timestamp))
df_log = df_log.withColumn(&quot;day&quot;, get_day(df_log.timestamp))
df_log = df_log.withColumn(&quot;week&quot;, get_week(df_log.timestamp))
df_log = df_log.withColumn(&quot;month&quot;, get_month(df_log.timestamp))
df_log = df_log.withColumn(&quot;year&quot;, get_year(df_log.timestamp))
df_log = df_log.withColumn(&quot;weekday&quot;, get_weekday(df_log.timestamp))
df_log.limit(5).toPandas()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist</th>
      <th>auth</th>
      <th>firstName</th>
      <th>gender</th>
      <th>itemInSession</th>
      <th>lastName</th>
      <th>length</th>
      <th>level</th>
      <th>location</th>
      <th>method</th>
      <th>...</th>
      <th>ts</th>
      <th>userAgent</th>
      <th>userId</th>
      <th>timestamp</th>
      <th>hour</th>
      <th>day</th>
      <th>week</th>
      <th>month</th>
      <th>year</th>
      <th>weekday</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Harmonia</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>0</td>
      <td>Smith</td>
      <td>655.77751</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>...</td>
      <td>1542241826796</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
      <td>2018-11-15 00:30:26.796</td>
      <td>0</td>
      <td>15</td>
      <td>46</td>
      <td>11</td>
      <td>2018</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The Prodigy</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>1</td>
      <td>Smith</td>
      <td>260.07465</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>...</td>
      <td>1542242481796</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
      <td>2018-11-15 00:41:21.796</td>
      <td>0</td>
      <td>15</td>
      <td>46</td>
      <td>11</td>
      <td>2018</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Train</td>
      <td>Logged In</td>
      <td>Ryan</td>
      <td>M</td>
      <td>2</td>
      <td>Smith</td>
      <td>205.45261</td>
      <td>free</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>PUT</td>
      <td>...</td>
      <td>1542242741796</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>26</td>
      <td>2018-11-15 00:45:41.796</td>
      <td>0</td>
      <td>15</td>
      <td>46</td>
      <td>11</td>
      <td>2018</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sony Wonder</td>
      <td>Logged In</td>
      <td>Samuel</td>
      <td>M</td>
      <td>0</td>
      <td>Gonzalez</td>
      <td>218.06975</td>
      <td>free</td>
      <td>Houston-The Woodlands-Sugar Land, TX</td>
      <td>PUT</td>
      <td>...</td>
      <td>1542253449796</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>61</td>
      <td>2018-11-15 03:44:09.796</td>
      <td>3</td>
      <td>15</td>
      <td>46</td>
      <td>11</td>
      <td>2018</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Van Halen</td>
      <td>Logged In</td>
      <td>Tegan</td>
      <td>F</td>
      <td>2</td>
      <td>Levine</td>
      <td>289.38404</td>
      <td>paid</td>
      <td>Portland-South Portland, ME</td>
      <td>PUT</td>
      <td>...</td>
      <td>1542260935796</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>80</td>
      <td>2018-11-15 05:48:55.796</td>
      <td>5</td>
      <td>15</td>
      <td>46</td>
      <td>11</td>
      <td>2018</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div>
<pre><code class="language-python">time_cols = [&quot;timestamp&quot;, &quot;hour&quot;, &quot;day&quot;, &quot;week&quot;, &quot;month&quot;, &quot;year&quot;, &quot;weekday&quot;]
</code></pre>
<pre><code class="language-python">time_table_df = df_log.select(time_cols)
</code></pre>
<pre><code class="language-python"># write to parquet file partition by 
time_table_df.write.parquet('data/time_table', partitionBy=['year', 'month'], mode='Overwrite')
</code></pre>
<pre><code class="language-python"># write this to s3 bucket
time_table_df.write.parquet(output + 'time_table', partitionBy=['year', 'month'], mode='Overwrite')
</code></pre>
<h2 id="songplay-table">SongPlay table</h2>
<pre><code class="language-python">df_log.printSchema()
</code></pre>
<pre><code>root
 |-- artist: string (nullable = true)
 |-- auth: string (nullable = true)
 |-- firstName: string (nullable = true)
 |-- gender: string (nullable = true)
 |-- itemInSession: long (nullable = true)
 |-- lastName: string (nullable = true)
 |-- length: double (nullable = true)
 |-- level: string (nullable = true)
 |-- location: string (nullable = true)
 |-- method: string (nullable = true)
 |-- page: string (nullable = true)
 |-- registration: double (nullable = true)
 |-- sessionId: long (nullable = true)
 |-- song: string (nullable = true)
 |-- status: long (nullable = true)
 |-- ts: long (nullable = true)
 |-- userAgent: string (nullable = true)
 |-- userId: string (nullable = true)
 |-- timestamp: timestamp (nullable = true)
 |-- hour: integer (nullable = true)
 |-- day: integer (nullable = true)
 |-- week: integer (nullable = true)
 |-- month: integer (nullable = true)
 |-- year: integer (nullable = true)
 |-- weekday: integer (nullable = true)
</code></pre>
<pre><code class="language-python">songplay_cols_temp = [&quot;timestamp&quot;, &quot;userId&quot;, &quot;sessionId&quot;, &quot;location&quot;, &quot;userAgent&quot;, &quot;level&quot;]
</code></pre>
<pre><code class="language-python">df_log.select(songplay_cols).toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>timestamp</th>
      <th>userId</th>
      <th>sessionId</th>
      <th>location</th>
      <th>userAgent</th>
      <th>level</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2018-11-15 00:30:26.796</td>
      <td>26</td>
      <td>583</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>free</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018-11-15 00:41:21.796</td>
      <td>26</td>
      <td>583</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>free</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2018-11-15 00:45:41.796</td>
      <td>26</td>
      <td>583</td>
      <td>San Jose-Sunnyvale-Santa Clara, CA</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>free</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2018-11-15 03:44:09.796</td>
      <td>61</td>
      <td>597</td>
      <td>Houston-The Woodlands-Sugar Land, TX</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>free</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2018-11-15 05:48:55.796</td>
      <td>80</td>
      <td>602</td>
      <td>Portland-South Portland, ME</td>
      <td>"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>
      <td>paid</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python"># read the partitioned data
df_artists_read = spark.read.option(&quot;mergeSchema&quot;, &quot;true&quot;).parquet(&quot;data/artists_table&quot;)
df_songs_read = spark.read.option(&quot;mergeSchema&quot;, &quot;true&quot;).parquet(&quot;data/songs_table&quot;)
</code></pre>
<pre><code class="language-python">df_artists_read.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist_id</th>
      <th>artist_name</th>
      <th>artist_location</th>
      <th>artist_latitude</th>
      <th>artist_longitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ARDR4AC1187FB371A1</td>
      <td>Montserrat Caballé;Placido Domingo;Vicente Sar...</td>
      <td></td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AREBBGV1187FB523D2</td>
      <td>Mike Jones (Featuring CJ_ Mello &amp; Lil' Bran)</td>
      <td>Houston, TX</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ARMAC4T1187FB3FA4C</td>
      <td>The Dillinger Escape Plan</td>
      <td>Morris Plains, NJ</td>
      <td>40.82624</td>
      <td>-74.47995</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ARPBNLO1187FB3D52F</td>
      <td>Tiny Tim</td>
      <td>New York, NY</td>
      <td>40.71455</td>
      <td>-74.00712</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ARDNS031187B9924F0</td>
      <td>Tim Wilson</td>
      <td>Georgia</td>
      <td>32.67828</td>
      <td>-83.22295</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">df_songs_read.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_id</th>
      <th>title</th>
      <th>duration</th>
      <th>year</th>
      <th>artist_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SOAOIBZ12AB01815BE</td>
      <td>I Hold Your Hand In Mine [Live At Royal Albert...</td>
      <td>43.36281</td>
      <td>2000</td>
      <td>ARPBNLO1187FB3D52F</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SONYPOM12A8C13B2D7</td>
      <td>I Think My Wife Is Running Around On Me (Taco ...</td>
      <td>186.48771</td>
      <td>2005</td>
      <td>ARDNS031187B9924F0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SODREIN12A58A7F2E5</td>
      <td>A Whiter Shade Of Pale (Live @ Fillmore West)</td>
      <td>326.00771</td>
      <td>0</td>
      <td>ARLTWXK1187FB5A3F8</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SOYMRWW12A6D4FAB14</td>
      <td>The Moon And I (Ordinary Day Album Version)</td>
      <td>267.70240</td>
      <td>0</td>
      <td>ARKFYS91187B98E58F</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>Streets On Fire (Explicit Album Version)</td>
      <td>279.97995</td>
      <td>0</td>
      <td>ARPFHN61187FB575F6</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python"># merge song and artists
df_songs_read.join(df_artists_read, 'artist_id').toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>artist_id</th>
      <th>song_id</th>
      <th>title</th>
      <th>duration</th>
      <th>year</th>
      <th>artist_name</th>
      <th>artist_location</th>
      <th>artist_latitude</th>
      <th>artist_longitude</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ARPBNLO1187FB3D52F</td>
      <td>SOAOIBZ12AB01815BE</td>
      <td>I Hold Your Hand In Mine [Live At Royal Albert...</td>
      <td>43.36281</td>
      <td>2000</td>
      <td>Tiny Tim</td>
      <td>New York, NY</td>
      <td>40.71455</td>
      <td>-74.00712</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ARDNS031187B9924F0</td>
      <td>SONYPOM12A8C13B2D7</td>
      <td>I Think My Wife Is Running Around On Me (Taco ...</td>
      <td>186.48771</td>
      <td>2005</td>
      <td>Tim Wilson</td>
      <td>Georgia</td>
      <td>32.67828</td>
      <td>-83.22295</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ARLTWXK1187FB5A3F8</td>
      <td>SODREIN12A58A7F2E5</td>
      <td>A Whiter Shade Of Pale (Live @ Fillmore West)</td>
      <td>326.00771</td>
      <td>0</td>
      <td>King Curtis</td>
      <td>Fort Worth, TX</td>
      <td>32.74863</td>
      <td>-97.32925</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ARKFYS91187B98E58F</td>
      <td>SOYMRWW12A6D4FAB14</td>
      <td>The Moon And I (Ordinary Day Album Version)</td>
      <td>267.70240</td>
      <td>0</td>
      <td>Jeff And Sheri Easter</td>
      <td></td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ARPFHN61187FB575F6</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>Streets On Fire (Explicit Album Version)</td>
      <td>279.97995</td>
      <td>0</td>
      <td>Lupe Fiasco</td>
      <td>Chicago, IL</td>
      <td>41.88415</td>
      <td>-87.63241</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">df_joined_songs_artists = df_songs_read.join(df_artists_read, 'artist_id').select(&quot;artist_id&quot;, &quot;song_id&quot;, &quot;title&quot;, &quot;artist_name&quot;)
</code></pre>
<pre><code class="language-python">songplay_cols = [&quot;timestamp&quot;, &quot;userId&quot;, &quot;song_id&quot;, &quot;artist_id&quot;, &quot;sessionId&quot;, &quot;location&quot;, &quot;userAgent&quot;, &quot;level&quot;, &quot;month&quot;, &quot;year&quot;]
</code></pre>
<pre><code class="language-python"># join df_logs with df_joined_songs_artists
df_log.join(df_joined_songs_artists, df_log.artist == df_joined_songs_artists.artist_name).select(songplay_cols).toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>timestamp</th>
      <th>userId</th>
      <th>song_id</th>
      <th>artist_id</th>
      <th>sessionId</th>
      <th>location</th>
      <th>userAgent</th>
      <th>level</th>
      <th>month</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2018-11-10 07:47:51.796</td>
      <td>44</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>350</td>
      <td>Waterloo-Cedar Falls, IA</td>
      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...</td>
      <td>paid</td>
      <td>11</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018-11-06 18:34:31.796</td>
      <td>97</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>293</td>
      <td>Lansing-East Lansing, MI</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>paid</td>
      <td>11</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2018-11-06 16:04:44.796</td>
      <td>2</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>126</td>
      <td>Plymouth, IN</td>
      <td>"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>
      <td>free</td>
      <td>11</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2018-11-28 23:22:57.796</td>
      <td>24</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>984</td>
      <td>Lake Havasu City-Kingman, AZ</td>
      <td>"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>
      <td>paid</td>
      <td>11</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2018-11-14 13:11:26.796</td>
      <td>34</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>495</td>
      <td>Milwaukee-Waukesha-West Allis, WI</td>
      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...</td>
      <td>free</td>
      <td>11</td>
      <td>2018</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">songplay_table_df = df_log.join(df_joined_songs_artists, df_log.artist == df_joined_songs_artists.artist_name).select(songplay_cols)
songplay_table_df = songplay_table_df.withColumn(&quot;songplay_id&quot;, F.monotonically_increasing_id())
</code></pre>
<pre><code class="language-python">songplay_table_df.toPandas().head()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>timestamp</th>
      <th>userId</th>
      <th>song_id</th>
      <th>artist_id</th>
      <th>sessionId</th>
      <th>location</th>
      <th>userAgent</th>
      <th>level</th>
      <th>month</th>
      <th>year</th>
      <th>songplay_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2018-11-10 07:47:51.796</td>
      <td>44</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>350</td>
      <td>Waterloo-Cedar Falls, IA</td>
      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...</td>
      <td>paid</td>
      <td>11</td>
      <td>2018</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2018-11-06 18:34:31.796</td>
      <td>97</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>293</td>
      <td>Lansing-East Lansing, MI</td>
      <td>"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>
      <td>paid</td>
      <td>11</td>
      <td>2018</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2018-11-06 16:04:44.796</td>
      <td>2</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>126</td>
      <td>Plymouth, IN</td>
      <td>"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>
      <td>free</td>
      <td>11</td>
      <td>2018</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2018-11-28 23:22:57.796</td>
      <td>24</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>984</td>
      <td>Lake Havasu City-Kingman, AZ</td>
      <td>"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>
      <td>paid</td>
      <td>11</td>
      <td>2018</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2018-11-14 13:11:26.796</td>
      <td>34</td>
      <td>SOWQTQZ12A58A7B63E</td>
      <td>ARPFHN61187FB575F6</td>
      <td>495</td>
      <td>Milwaukee-Waukesha-West Allis, WI</td>
      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; r...</td>
      <td>free</td>
      <td>11</td>
      <td>2018</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python"># write this to parquet file
# write to parquet file partition by 
songplay_table_df.write.parquet('data/songplays_table', partitionBy=['year', 'month'], mode='Overwrite')
</code></pre>
<pre><code class="language-python">
</code></pre>
<pre><code class="language-python">
</code></pre>
<pre><code class="language-python">
</code></pre>
<pre><code class="language-python">from pyspark.sql import functions as F
</code></pre>
<pre><code class="language-python">from glob import glob
</code></pre>
<pre><code class="language-python">test_df = spark.read.json(glob(&quot;test/*.json&quot;))
</code></pre>
<pre><code class="language-python">test_df.select(['song_id', 'title', 'artist_id', 'year', 'duration']).toPandas()
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_id</th>
      <th>title</th>
      <th>artist_id</th>
      <th>year</th>
      <th>duration</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SOYMRWW12A6D4FAB14</td>
      <td>The Moon And I (Ordinary Day Album Version)</td>
      <td>ARKFYS91187B98E58F</td>
      <td>0</td>
      <td>267.70240</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SOHKNRJ12A6701D1F8</td>
      <td>Drop of Rain</td>
      <td>AR10USD1187B99F3F1</td>
      <td>0</td>
      <td>189.57016</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SOYMRWW12A6D4FAB14</td>
      <td>The Moon And SUN</td>
      <td>ASKFYS91187B98E58F</td>
      <td>0</td>
      <td>269.70240</td>
    </tr>
    <tr>
      <th>3</th>
      <td>SOUDSGM12AC9618304</td>
      <td>Insatiable (Instrumental Version)</td>
      <td>ARNTLGG11E2835DDB9</td>
      <td>0</td>
      <td>266.39628</td>
    </tr>
  </tbody>
</table>
</div>
<pre><code class="language-python">test_df.select(['song_id', 'title', 'artist_id', 'year', 'duration']).groupBy('song_id').count().show()
</code></pre>
<pre><code>+------------------+-----+
|           song_id|count|
+------------------+-----+
|SOUDSGM12AC9618304|    1|
|SOYMRWW12A6D4FAB14|    2|
|SOHKNRJ12A6701D1F8|    1|
+------------------+-----+
</code></pre>
<pre><code class="language-python">test_df.select(F.col('song_id'), 'title') \
    .groupBy('song_id') \
    .agg({'title': 'first'}) \
    .withColumnRenamed('first(title)', 'title1') \
    .show()
</code></pre>
<pre><code>+------------------+--------------------+
|           song_id|               title|
+------------------+--------------------+
|SOUDSGM12AC9618304|Insatiable (Instr...|
|SOYMRWW12A6D4FAB14|The Moon And I (O...|
|SOHKNRJ12A6701D1F8|        Drop of Rain|
+------------------+--------------------+
</code></pre>
<pre><code class="language-python">t1 = test_df.select(F.col('song_id'), 'title') \
    .groupBy('song_id') \
    .agg({'title': 'first'}) \
    .withColumnRenamed('first(title)', 'title1')
</code></pre>
<pre><code class="language-python">t2 = test_df.select(['song_id', 'title', 'artist_id', 'year', 'duration'])
</code></pre>
<pre><code class="language-python">t1.join(t2, 'song_id').where(F.col(&quot;title1&quot;) == F.col(&quot;title&quot;)).select([&quot;song_id&quot;, &quot;title&quot;, &quot;artist_id&quot;, &quot;year&quot;, &quot;duration&quot;]).show()
</code></pre>
<pre><code>+------------------+--------------------+------------------+----+---------+
|           song_id|               title|         artist_id|year| duration|
+------------------+--------------------+------------------+----+---------+
|SOYMRWW12A6D4FAB14|The Moon And I (O...|ARKFYS91187B98E58F|   0| 267.7024|
|SOHKNRJ12A6701D1F8|        Drop of Rain|AR10USD1187B99F3F1|   0|189.57016|
|SOUDSGM12AC9618304|Insatiable (Instr...|ARNTLGG11E2835DDB9|   0|266.39628|
+------------------+--------------------+------------------+----+---------+
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 7 - Semaphore vs Lock Example]]></title>
        <id>https://blog.ferretninja.com/post/java-juc-javautilconcurrent-7-semaphore-vs-lock-example/</id>
        <link href="https://blog.ferretninja.com/post/java-juc-javautilconcurrent-7-semaphore-vs-lock-example/">
        </link>
        <updated>2021-03-29T09:34:58.000Z</updated>
        <content type="html"><![CDATA[<p><strong>1114. Print in Order</strong></p>
<pre><code>class Foo {
    
    private volatile boolean onePrinted;
    private volatile boolean twoPrinted;

    public Foo() {
        onePrinted = false;
        twoPrinted = false;        
    }

    public synchronized void first(Runnable printFirst) throws InterruptedException {
        
        // printFirst.run() outputs &quot;first&quot;. Do not change or remove this line.
        printFirst.run();
        onePrinted = true;
        notifyAll();
    }

    public synchronized void second(Runnable printSecond) throws InterruptedException {
        while(!onePrinted) {
            wait();
        }
        // printSecond.run() outputs &quot;second&quot;. Do not change or remove this line.
        printSecond.run();
        twoPrinted = true;
        notifyAll();
    }

    public synchronized void third(Runnable printThird) throws InterruptedException {
        while(!twoPrinted) {
            wait();
        }
        // printThird.run() outputs &quot;third&quot;. Do not change or remove this line.
        printThird.run();
    }
}
</code></pre>
<pre><code>import java.util.concurrent.*;
class Foo {
    Semaphore run2, run3;

    public Foo() {
        run2 = new Semaphore(0);
        run3 = new Semaphore(0);
    }

    public void first(Runnable printFirst) throws InterruptedException {
        printFirst.run();
        run2.release();
    }

    public void second(Runnable printSecond) throws InterruptedException {
        run2.acquire();
        printSecond.run();
        run3.release();
    }

    public void third(Runnable printThird) throws InterruptedException {
        run3.acquire(); 
        printThird.run();
    }
}
</code></pre>
<p><strong>1188. Design Bounded Blocking Queue</strong></p>
<p>When await() is called, the lock associated with this Condition is atomically released and the current thread becomes disabled for thread scheduling purposes. The current thread is assumed to hold the lock associated with this Condition when this method is called.</p>
<p>newCondition()<br>
await/signal/signalAll</p>
<p>synchonized<br>
wait/notify/notifyAll</p>
<p>The ReentrantLock is an exclusive lock so only one thread can acquire the lock.<br>
See #1. When a thread call signal or signalAll, it releases respectively one thread or all threads awaiting for the corresponding Condition such that the thread or those threads will be eligible to acquire the lock again. But for now the lock is still owned by the thread that called signal or signalAll until it releases explicitly the lock by calling lock.unlock(). Then the thread(s) that has/have been released will be able to try to acquire the lock again, the thread that could acquire the lock will be able to check the condition again (by condition this time I mean count == items.length or count == 0 in this example), if it is ok it will proceed otherwise it will await again and release the lock to make it available to another thread.</p>
<pre><code>class BoundedBlockingQueue {
    
    private Queue&lt;Integer&gt; queue;
    private Semaphore consumerSemaphore;
    private Semaphore producerSemaphore;
    private Semaphore mutex;

    public BoundedBlockingQueue(int capacity) {
        this.queue = new LinkedList&lt;&gt;();
        this.producerSemaphore = new Semaphore(capacity);
        this.consumerSemaphore = new Semaphore(0);
        this.mutex = new Semaphore(1);
    }

    public void enqueue(int element) throws InterruptedException {
        this.producerSemaphore.acquire();
        //use mutex with Linkedlist or use ConcurrentLinkedDeque&lt;Integer&gt; q without mutex
        this.mutex.acquire();                  
        this.queue.offer(element);
        this.mutex.release();
        this.consumerSemaphore.release();
    }

    public int dequeue() throws InterruptedException {
        this.consumerSemaphore.acquire();
        this.mutex.acquire();
        Integer res = this.queue.poll();
        this.mutex.release();
        this.producerSemaphore.release();
        return res == null ? -1 : res;
    }

    public int size() {
        return this.queue.size();
    }
}


class BoundedBlockingQueue {
    
    private Queue&lt;Integer&gt; queue;
    
    private int capacity;

    public BoundedBlockingQueue(int capacity) {
        this.capacity = capacity;
        this.queue = new LinkedList&lt;&gt;();
    }
    
    public void enqueue(int element) throws InterruptedException {
        //object level synchronized so either enqueu or dequeue can run
        synchronized(this) {
            while (this.queue.size() == this.capacity) {
                wait();
            }
            this.queue.offer(element);
            notifyAll();
        }
    }
    
    public int dequeue() throws InterruptedException {
        synchronized(this) {
            while (this.queue.isEmpty()) {
                wait();
            }
            int res = this.queue.poll();
            notifyAll();
            return res;
        }
    }
    
    public int size() {
        return this.queue.size();
    }
}


class BoundedBlockingQueue {

    private int[] data;
    private int capacity = 0, head = 0, tail = 0;
    private volatile int size = 0;
    private Lock lock = new ReentrantLock();
    private Condition isFull = lock.newCondition(), isEmpty = lock.newCondition();
    
    public BoundedBlockingQueue(int capacity) {
        this.data = new int[capacity];
        this.capacity = capacity;
    }
    
    public void enqueue(int element) throws InterruptedException {
        try {
            lock.lock();  
            while (size == capacity) {
                isFull.await();     // only one thread will get lock after all threads wake up by signalAll().
            }
            data[tail++ % capacity] = element;
            size++;
            isEmpty.signalAll();
        } catch(InterruptedException e) {
        } finally {
            lock.unlock();
        }
    }
    
    public int dequeue() throws InterruptedException {
        int res = 0;
        try {
            lock.lock();
            while (size == 0) {
                isEmpty.await();
            }
            isFull.signalAll();
            res = data[head++ % capacity];
            size--;
        } catch(InterruptedException e) {
        } finally {
            lock.unlock();
        }
        return res;
    }
    
    public int size() {
        return size;
    }
}
</code></pre>
<p>In order for the two methods to run concurrently they would have to use different locks</p>
<pre><code>class A {
    private final Object lockA = new Object();
    private final Object lockB = new Object();

    public void methodA() {
        synchronized(lockA) {
            //method A
        }
    }

    public void methodB() {
        synchronized(lockB) {
            //method B
        }
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 6 - Exception]]></title>
        <id>https://blog.ferretninja.com/post/java-juc-javautilconcurrent-6-exception/</id>
        <link href="https://blog.ferretninja.com/post/java-juc-javautilconcurrent-6-exception/">
        </link>
        <updated>2021-03-29T09:34:39.000Z</updated>
        <content type="html"><![CDATA[<p>To stop a thread</p>
<ol>
<li>stop()  // deprecated<br>
throws ThreadDeath exception and release lock</li>
<li>interrupt()   // isInterrupted()</li>
</ol>
<pre><code>public class MyThread extends Thread {
    @Override
    public void run() {
        try {
            for (int i=0; i&lt;50000; i++){
                if (this.isInterrupted()) {
                    System.out.println(&quot; 已经是停止状态了！&quot;);
                    throw new InterruptedException();   // or intead use return;
                }
                System.out.println(i);
            }
            System.out.println(&quot; 不抛出异常，我会被执行的哦！&quot;);
        } catch (Exception e) {
//            e.printStackTrace();
        }
    }
 
    public static void main(String[] args) throws InterruptedException {
        MyThread myThread =new MyThread();
        myThread.start();
        Thread.sleep(100);
        myThread.interrupt();
    }
 
}
</code></pre>
<p>suspend() and resume() // deprecated because occupy lock</p>
<p>suspend can block println()</p>
<pre><code>public void println(String x) {
		synchronized (this) {
				print(x);
				newLine();
		}
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://blog.ferretninja.com/post-images/1572150142349.jpg" alt="" loading="lazy"></figure>
<p><strong>uncaughtException</strong></p>
<pre><code>ThreadGroup group = new ThreadGroup(&quot;&quot;){
      @Override
      public void uncaughtException(Thread t, Throwable e) {
             super.uncaughtException(t, e);
             // 一个线程出现异常，中断组内所有线程
             this.interrupt();
      }
};
</code></pre>
<pre><code>public class MyThread{
 
    public static void main(String[] args) {
        ThreadGroup threadGroup = new ThreadGroup(&quot;ThreadGroup&quot;){
            @Override
            public void uncaughtException(Thread t, Throwable e) {
                System.out.println(&quot; 线程组的异常处理 &quot;);
                super.uncaughtException(t, e);
            }
        };
        Thread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
            @Override
            public void uncaughtException(Thread t, Throwable e) {
                System.out.println(&quot; 线程类的异常处理 &quot;);
            }
        });
        Thread thread = new Thread(threadGroup,&quot;Thread&quot;){
            @Override
            public void run() {
                System.out.println(Thread.currentThread().getName()+&quot; 执行 &quot;);
                int i= 2/0;
            }
        };
//        thread.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
//            @Override
//            public void uncaughtException(Thread t, Throwable e) {
//                System.out.println(&quot; 线程对象的异常处理 &quot;);
//            }
//        });
        thread.start();
    }
 
}

//Thread 执行
//线程组的异常处理
//线程类的异常处理

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 5 - ThreadPool and ThreadLocal]]></title>
        <id>https://blog.ferretninja.com/post/java-juc-javautilconcurrent-5-threadpool-and-threadlocal/</id>
        <link href="https://blog.ferretninja.com/post/java-juc-javautilconcurrent-5-threadpool-and-threadlocal/">
        </link>
        <updated>2021-03-29T09:34:25.000Z</updated>
        <content type="html"><![CDATA[<p>Java use Thread Pool pattern to save resources in a multithreaded application, and also to contain the parallelism in certain predefined limits. It controls several re-used threads for executing these tasks.</p>
<pre><code>ExecutorService executorService = Executors.newCachedThreadPool();
for (int i = 0; i &lt; 10; i++) {
		final int index = i;
		executorService.execute(new Runnable() {
				@Override
				public void run() {
						log.info(&quot;task:{}&quot;, index);
				}
		});
}
executorService.shutdown();
</code></pre>
<p>There are several pre-defined threadpool for various scenarios.</p>
<pre><code>ExecutorService executorService = Executors.newFixedThreadPool(3);
ExecutorService executorService = Executors.newSingleThreadExecutor();
ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);
</code></pre>
<p><strong>newFixedThreadPool = ThreadPoolExecutor with default</strong></p>
<pre><code> public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue&lt;Runnable&gt;());
}
</code></pre>
<p>The TheadLocal construct allows us to store data that will be accessible only by a specific thread.</p>
<pre><code>private final static ThreadLocal&lt;Long&gt; requestHolder = new ThreadLocal&lt;&gt;();
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 4 - Lock]]></title>
        <id>https://blog.ferretninja.com/post/java-juc-javautilconcurrent-4-lock/</id>
        <link href="https://blog.ferretninja.com/post/java-juc-javautilconcurrent-4-lock/">
        </link>
        <updated>2021-03-29T09:34:00.000Z</updated>
        <content type="html"><![CDATA[<p>Compare to <code>synchronized</code> keyword, Locks support various methods for finer grained control thus are more expressive than <code>synchronized</code>.</p>
<p>Since <code>synchronized</code> keyword create lock implicitly, one can convert the  <code>synchronized</code> keyword to ReentrantLock.</p>
<pre><code>private synchronized static void add() {
        count++;
}
</code></pre>
<pre><code>private final static Lock lock = new ReentrantLock();
private static void add() {
		lock.lock();
		try {
				count++;
		} finally {
				lock.unlock();
		}
}
</code></pre>
<p>Therefore, it is possible for both <code>synchronized</code> and Lock to introduce the well-know deadlock problem like below.</p>
<pre><code>public class DeadLock implements Runnable {
    public int flag = 1;
    //静态对象是类的所有对象共享的
    private static Object o1 = new Object(), o2 = new Object();

    @Override
    public void run() {
        log.info(&quot;flag:{}&quot;, flag);
        if (flag == 1) {
            synchronized (o1) {
                try {
                    Thread.sleep(500);
                } catch (Exception e) {
                    e.printStackTrace();
                }
                synchronized (o2) {
                    log.info(&quot;1&quot;);
                }
            }
        }
        if (flag == 0) {
            synchronized (o2) {
                try {
                    Thread.sleep(500);
                } catch (Exception e) {
                    e.printStackTrace();
                }
                synchronized (o1) {
                    log.info(&quot;0&quot;);
                }
            }
        }
    }

    public static void main(String[] args) {
        DeadLock td1 = new DeadLock();
        DeadLock td2 = new DeadLock();
        td1.flag = 1;
        td2.flag = 0;
        //td1,td2都处于可执行状态，但JVM线程调度先执行哪个线程是不确定的。
        //td2的run()可能在td1的run()之前运行
        new Thread(td1).start();
        new Thread(td2).start();
    }
}
</code></pre>
<p>The <code>synchronized</code> keyword provides a simplified model while Lock offers more APIs such as ReentrantReadWriteLock and Condition. The interface ReadWriteLock specifies a pair of locks for read and write access. This can improve performance and throughput in cases where write-accesses are much less frequent.</p>
<pre><code>private final Map&lt;String, Data&gt; map = new TreeMap&lt;&gt;();

private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
private final Lock readLock = lock.readLock();
private final Lock writeLock = lock.writeLock();

public Data get(String key) {
		readLock.lock();
		try {
				return map.get(key);
		} finally {
				readLock.unlock();
		}
}

public Data put(String key, Data value) {
		writeLock.lock();
		try {
				return map.put(key, value);
		} finally {
				writeLock.unlock();
		}
}
</code></pre>
<p><code>Condition.signalAll()</code> is a very important API in consumer-producer model.</p>
<pre><code>public static void main(String[] args) {
		ReentrantLock reentrantLock = new ReentrantLock();
		Condition condition = reentrantLock.newCondition();

		new Thread(() -&gt; {
				try {
						reentrantLock.lock();
						log.info(&quot;wait signal&quot;); // 1
						condition.await();
				} catch (InterruptedException e) {
						e.printStackTrace();
				}
				log.info(&quot;get signal&quot;); // 4
				reentrantLock.unlock();
		}).start();

		new Thread(() -&gt; {
				reentrantLock.lock();
				log.info(&quot;get lock&quot;); // 2
				try {
						Thread.sleep(3000);
				} catch (InterruptedException e) {
						e.printStackTrace();
				}
				condition.signalAll();
				log.info(&quot;send signal ~ &quot;); // 3
				reentrantLock.unlock();
		}).start();
}
</code></pre>
]]></content>
    </entry>
</feed>